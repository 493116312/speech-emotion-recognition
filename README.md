# speech-emotion-recognition
Detecting emotions using MFCC features of human speech using Deep Learning

In this project we will use Mel frequency cepstral coefficients (MFCC) to train a recurrent neural network (LSTM) and classify human emotions into happy, sad, angry, frustrated, sad, neutral and fear categories.

#### The dataset used is The Interactive Emotional Dyadic Motion Capture (IEMOCAP) collected by University of Southern California
the link for the same can be found [here](http://sail.usc.edu/iemocap/)


More files coming soon...
